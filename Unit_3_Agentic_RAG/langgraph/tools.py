from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.tools import Tool
import random
from langchain_core.tools import Tool
from huggingface_hub import list_models
from typing import TypedDict, Annotated
from langgraph.graph.message import add_messages
from langchain_core.messages import AnyMessage, HumanMessage, AIMessage
from langgraph.prebuilt import ToolNode
from langgraph.graph import START, StateGraph
from langgraph.prebuilt import tools_condition
from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace

search_tool = DuckDuckGoSearchRun()
results = search_tool.invoke("Who's the current President of France?")
print(results)

def get_weather_info(location: str) -> str:
    """Fetches dummy weather information for a given location."""
    # è™šæ‹Ÿå¤©æ°”æ•°æ®
    weather_conditions = [
        {"condition": "Rainy", "temp_c": 15},
        {"condition": "Clear", "temp_c": 25},
        {"condition": "Windy", "temp_c": 20}
    ]
    # éšæœºé€‰æ‹©ä¸€ç§å¤©æ°”çŠ¶å†µ
    data = random.choice(weather_conditions)
    return f"Weather in {location}: {data['condition']}, {data['temp_c']}Â°C"

# åˆå§‹åŒ–å·¥å…·
weather_info_tool = Tool(
    name="get_weather_info",
    func=get_weather_info,
    description="Fetches dummy weather information for a given location."
)


def get_hub_stats(author: str) -> str:
    """Fetches the most downloaded model from a specific author on the Hugging Face Hub."""
    try:
        # åˆ—å‡ºæŒ‡å®šä½œè€…çš„æ¨¡å‹ï¼ŒæŒ‰ä¸‹è½½æ¬¡æ•°æ’åº
        models = list(list_models(author=author, sort="downloads", direction=-1, limit=1))

        if models:
            model = models[0]
            return f"The most downloaded model by {author} is {model.id} with {model.downloads:,} downloads."
        else:
            return f"No models found for author {author}."
    except Exception as e:
        return f"Error fetching models for {author}: {str(e)}"

# åˆå§‹åŒ–å·¥å…·
hub_stats_tool = Tool(
    name="get_hub_stats",
    func=get_hub_stats,
    description="Fetches the most downloaded model from a specific author on the Hugging Face Hub."
)

# ç¤ºä¾‹ç”¨æ³•
print(hub_stats_tool.invoke("facebook")) # Example: Get the most downloaded model by Facebook


# ç”ŸæˆèŠå¤©ç•Œé¢ï¼ŒåŒ…æ‹¬å·¥å…·
llm = HuggingFaceEndpoint(
    repo_id="Qwen/Qwen2.5-7B-Instruct",
    huggingfacehub_api_token="",
)

chat = ChatHuggingFace(llm=llm, verbose=True)
tools = [search_tool, weather_info_tool, hub_stats_tool]
chat_with_tools = chat.bind_tools(tools)

# ç”Ÿæˆ AgentState å’Œ Agent å›¾
class AgentState(TypedDict):
    messages: Annotated[list[AnyMessage], add_messages]

def assistant(state: AgentState):
    return {
        "messages": [chat_with_tools.invoke(state["messages"])],
    }

## æ„å»ºæµç¨‹å›¾
builder = StateGraph(AgentState)

# å®šä¹‰èŠ‚ç‚¹ï¼šè¿™äº›èŠ‚ç‚¹å®Œæˆå·¥ä½œ
builder.add_node("assistant", assistant)
builder.add_node("tools", ToolNode(tools))

# å®šä¹‰è¾¹ï¼šè¿™äº›å†³å®šäº†æ§åˆ¶æµå¦‚ä½•ç§»åŠ¨
builder.add_edge(START, "assistant")
builder.add_conditional_edges(
    "assistant",
    # If the latest message requires a tool, route to tools
    # Otherwise, provide a direct response
    tools_condition,
)
builder.add_edge("tools", "assistant")
alfred = builder.compile()

messages = [HumanMessage(content="Who is Facebook and what's their most popular model?")]
response = alfred.invoke({"messages": messages})

print("ğŸ© Alfred's Response:")
print(response['messages'][-1].content)